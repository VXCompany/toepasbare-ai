{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"RAG Demo 1\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://eu.api.smith.langchain.com\"\n",
    "os.environ[\"USER_AGENT\"] = \"MyRagDemo/1.0\"\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your Langsmith API key: \")"
   ],
   "id": "cfce04d1378a764e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RAG DEMO 1\n",
    "\n",
    "Allereerst maken we gebruik van een chat model, in dit geval die van OpenAi."
   ],
   "id": "419e372416997272"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ],
   "id": "47f53c7a61b12246",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vervolgens moeten we een provider kiezen voor onze embeddings model, ook hier OpenAI.",
   "id": "afac71e8a5cd7776"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ],
   "id": "f338ced035625ed8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "En een store voor onze vectors. Voor de demo is dit een In Memory store, maar kan ook Elasticsearch zijn o.i.d.",
   "id": "3ec1f79e0f33e020"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ],
   "id": "e1feb81900a177e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Inladen van de documenten\n",
    "Inladen van een tekst. In dit geval de Silmarillion van Tolkien.\n",
    "Toch best een lastig boek waar zelfs de meest die-hard fans nog massa's vragen over hebben."
   ],
   "id": "c89b4f128ba5b9aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep the text, skip the rest of the HTML.\n",
    "# Other example: parse_only=bs4.SoupStrainer(class_=(\"post-content\", \"post-title\", \"post-header\"))\n",
    "bs4_strainer = bs4.SoupStrainer(['pre'])\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://archive.org/stream/TheSilmarillionIllustratedJ.R.R.TolkienTedNasmith/The%20Silmarillion%20%28Illustrated%29%20-%20J.%20R.%20R.%20Tolkien%3B%20Ted%20Nasmith%3B_djvu.txt\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")\n",
    "#print(docs[0].page_content[:500])"
   ],
   "id": "8f140fe9db223229",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Splitsen van de documenten\n",
    "Ik gebruik hier een algemene splitter. Je hebt specifieke splitters voor code, academische papers, etc."
   ],
   "id": "d64a872b79d2eab9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split text into {len(all_splits)} sub-documents.\")"
   ],
   "id": "96f20f7d3f742443",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Opslaan van de chuncks\n",
    "Omdat we het embeddingsmodel gekoppeld hebben worden de embeddings gegenereerd en als vector opgeslagen."
   ],
   "id": "662b4559836e4fba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ],
   "id": "fa3483d147cc5dee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Aan de slag",
   "id": "76729c7ea55e9017"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ],
   "id": "7bbe78f2f5710fa5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RAG applicatie\n",
    "\n",
    "We gebruiken een State class om wat zaken bij te houden. In dit geval vraag, context en antwoord.\n",
    "Twee functies helpen bij de stappen voor het ophalen en het genereren van het antwoord."
   ],
   "id": "fcb79e2fb33d9951"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ],
   "id": "b41daa259d30cdf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Grappig: de graph ondersteunt Mermaid Diagrams, dus we kunnen onze simpele flow visualiseren:",
   "id": "510ec4303c17b5df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "6fca5f7609aa6f0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Uitvoeren",
   "id": "7ac3a49b59b61d66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "response = graph.invoke({\"question\": \"What is Tolkien's core message in the Silmarillion?\"})\n",
    "print(response[\"answer\"])"
   ],
   "id": "5cb74e28d1369f74",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
